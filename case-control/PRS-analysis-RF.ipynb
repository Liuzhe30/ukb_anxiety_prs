{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using Random Forest\n",
    "###### Step 1: Data Normalization\n",
    "###### Step 2: Shuffled model (permutation tests) for 100 times, with random labels\n",
    "###### Step 3: 10-fold validation for 100 DT models (generating 100*10 shuffled variable importances)\n",
    "###### Step 4: calculate mean values of variable importances (generating 10 mean shuffled variable importances, each feature 10 shuffled importances)\n",
    "###### Step 5: 10-fold validation for the real model (generating 10 real variable importances, each feature 10 real importances)\n",
    "###### Step 6: Significance testing for shuffled and real importances (Wilcoxon signed-rank test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301508, 413)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_anxiety</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>...</th>\n",
       "      <th>848</th>\n",
       "      <th>849</th>\n",
       "      <th>850</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>853</th>\n",
       "      <th>854</th>\n",
       "      <th>855</th>\n",
       "      <th>856</th>\n",
       "      <th>857</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000023</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025738</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>-5.377204e-07</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>-0.002815</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.014240</td>\n",
       "      <td>-0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000030</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>3.097558e-04</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>-0.005790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000041</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>-0.000921</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>1.148748e-04</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>-0.011370</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>-0.004178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>2.290053e-04</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.001964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000062</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>2.946820e-04</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>-0.006825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Is_anxiety       446       447       448       449       450  \\\n",
       "1000023           0  0.000507  0.002420 -0.000185 -0.000145 -0.000371   \n",
       "1000030           1  0.000276  0.001576  0.000038 -0.000381 -0.000399   \n",
       "1000041           0  0.000649 -0.000098 -0.000086  0.000090 -0.000678   \n",
       "1000059           0  0.000585  0.000814 -0.000066 -0.000621  0.000105   \n",
       "1000062           0  0.000214  0.001490  0.000117 -0.000153 -0.000603   \n",
       "\n",
       "              451       452       453       454  ...       848       849  \\\n",
       "1000023 -0.000873  0.012805  0.000115  0.000151  ...  0.025738 -0.001572   \n",
       "1000030 -0.004763  0.014032  0.000109  0.000093  ...  0.014733 -0.000623   \n",
       "1000041 -0.004804  0.007270 -0.000024  0.000109  ...  0.011649 -0.000921   \n",
       "1000059  0.001870  0.002563  0.000106  0.000097  ...  0.022186 -0.000923   \n",
       "1000062 -0.005913  0.012513  0.000089  0.000109  ...  0.022118 -0.000425   \n",
       "\n",
       "              850       851           852       853       854       855  \\\n",
       "1000023  0.014031 -0.000354 -5.377204e-07  0.000654 -0.002815 -0.000183   \n",
       "1000030  0.005552 -0.000244  3.097558e-04 -0.000190  0.000197 -0.000050   \n",
       "1000041  0.010997 -0.000557  1.148748e-04 -0.000354 -0.011370 -0.000419   \n",
       "1000059  0.015620 -0.000159  2.290053e-04 -0.000769  0.006247 -0.000164   \n",
       "1000062  0.007184  0.000349  2.946820e-04  0.001721  0.011161 -0.000200   \n",
       "\n",
       "              856       857  \n",
       "1000023  0.014240 -0.003520  \n",
       "1000030  0.012340 -0.005790  \n",
       "1000041  0.006975 -0.004178  \n",
       "1000059  0.001851 -0.001964  \n",
       "1000062  0.010253 -0.006825  \n",
       "\n",
       "[5 rows x 413 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# PRS dataset\n",
    "dataset = pd.read_pickle('datafile/PRS_dataset.pkl')\n",
    "dataset = dataset.fillna(0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>...</th>\n",
       "      <th>848</th>\n",
       "      <th>849</th>\n",
       "      <th>850</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>853</th>\n",
       "      <th>854</th>\n",
       "      <th>855</th>\n",
       "      <th>856</th>\n",
       "      <th>857</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000023</th>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>0.038436</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>0.042117</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>-0.008451</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.042746</td>\n",
       "      <td>-0.010566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000030</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>-0.001198</td>\n",
       "      <td>-0.014296</td>\n",
       "      <td>0.042122</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044224</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>-0.000570</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.037043</td>\n",
       "      <td>-0.017380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000041</th>\n",
       "      <td>0.001950</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>-0.014419</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>-0.010717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034966</td>\n",
       "      <td>-0.002765</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.001062</td>\n",
       "      <td>-0.034130</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>-0.012541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000059</th>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.028159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>0.046888</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>-0.002308</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>-0.005895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000062</th>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>-0.020703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066394</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.033502</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>0.030776</td>\n",
       "      <td>-0.020487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 412 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              446       447       448       449       450       451       452  \\\n",
       "1000023  0.001523  0.007263 -0.000556 -0.000436 -0.001114 -0.002620  0.038436   \n",
       "1000030  0.000827  0.004731  0.000113 -0.001145 -0.001198 -0.014296  0.042122   \n",
       "1000041  0.001950 -0.000294 -0.000258  0.000271 -0.002035 -0.014419  0.021824   \n",
       "1000059  0.001757  0.002443 -0.000198 -0.001865  0.000316  0.005612  0.007694   \n",
       "1000062  0.000643  0.004472  0.000351 -0.000460 -0.001809 -0.017750  0.037560   \n",
       "\n",
       "              453       454       455  ...       848       849       850  \\\n",
       "1000023  0.000345  0.000453  0.003520  ...  0.077259 -0.004720  0.042117   \n",
       "1000030  0.000327  0.000279  0.002764  ...  0.044224 -0.001871  0.016666   \n",
       "1000041 -0.000073  0.000327 -0.010717  ...  0.034966 -0.002765  0.033012   \n",
       "1000059  0.000318  0.000291  0.028159  ...  0.066598 -0.002770  0.046888   \n",
       "1000062  0.000266  0.000327 -0.020703  ...  0.066394 -0.001275  0.021566   \n",
       "\n",
       "              851       852       853       854       855       856       857  \n",
       "1000023 -0.001063 -0.000002  0.001963 -0.008451 -0.000549  0.042746 -0.010566  \n",
       "1000030 -0.000733  0.000930 -0.000570  0.000592 -0.000150  0.037043 -0.017380  \n",
       "1000041 -0.001673  0.000345 -0.001062 -0.034130 -0.001257  0.020937 -0.012541  \n",
       "1000059 -0.000478  0.000687 -0.002308  0.018753 -0.000494  0.005557 -0.005895  \n",
       "1000062  0.001049  0.000885  0.005165  0.033502 -0.000599  0.030776 -0.020487  \n",
       "\n",
       "[5 rows x 412 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1\n",
    "def normalization(data):\n",
    "    _range = np.max(np.max(abs(data)))\n",
    "    return data / _range\n",
    "\n",
    "nor_feature = dataset.drop(['Is_anxiety'], axis=1)\n",
    "nor_feature = normalization(nor_feature)\n",
    "nor_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle function\n",
    "import numpy as np\n",
    "def shuffle_f(a):\n",
    "    a = a.T\n",
    "    np.random.shuffle(a)\n",
    "    np.random.shuffle(a)\n",
    "    a = a.T\n",
    "    np.random.shuffle(a)\n",
    "    np.random.shuffle(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065\n",
      "max score：0.9065 subtree num：31\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyper-parameter tuning\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = nor_feature.values[0:10000]\n",
    "Y = dataset['Is_anxiety'].values[0:10000]\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=90)\n",
    "score_pre = cross_val_score(rfc, X, Y, cv=5).mean()\n",
    "print(score_pre)\n",
    "\n",
    "score_lt = []\n",
    "for i in range(0,200,10):\n",
    "    rfc = RandomForestClassifier(n_estimators=i+1\n",
    "                                ,random_state=90)\n",
    "    score = cross_val_score(rfc, X, Y, cv=5).mean()\n",
    "    score_lt.append(score)\n",
    "score_max = max(score_lt)\n",
    "print('max score：{}'.format(score_max),\n",
    "      'subtree num：{}'.format(score_lt.index(score_max)*10+1))\n",
    "\n",
    "\n",
    "x = np.arange(1,201,10)\n",
    "plt.subplot(111)\n",
    "plt.plot(x, score_lt, 'r-')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "# Step 2: Shuffled model (permutation tests) for 100 times, with random labels\n",
    "# Step 3: 10-fold validation for 100 DT models (generating 100*10 shuffled variable importances)\n",
    "Y = dataset['Is_anxiety'].values\n",
    "for i in tqdm(range(100)): # shuffle 100 times\n",
    "    X = shuffle_f(nor_feature.values)\n",
    "    # 10-fold\n",
    "    cv_result = []\n",
    "    cv = KFold(n_splits=10)\n",
    "    for train_index, valid_index in cv.split(X):\n",
    "        train_x,test_x = X[train_index], X[valid_index]\n",
    "        train_y,test_y = Y[train_index], Y[valid_index]\n",
    "        clf = RandomForestClassifier(n_estimators=50,random_state=90)\n",
    "        clf.fit(train_x, train_y)\n",
    "        feat_importance = clf.feature_importances_\n",
    "        cv_result.append(feat_importance)\n",
    "    importance = np.array(cv_result)\n",
    "    print(importance.shape) # expected 10 * 412\n",
    "    np.save('RF_importance_array/' + str(i) + '.npy', importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: calculate mean values of variable importances (generating 10 mean shuffled variable importances, each feature 10 shuffled importances)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "sum_array = np.zeros(shape=(10,412))\n",
    "for i in range(100):\n",
    "    RF_importance_array = np.load('RF_importance_array/' + str(i) + '.npy')\n",
    "    # print(DT_importance_array.shape) # (10, 412)\n",
    "    for j in range(10):\n",
    "        for k in range(412):\n",
    "            sum_array[j][k] += RF_importance_array[j][k]\n",
    "svg_array = sum_array/100\n",
    "print(svg_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: 10-fold validation for the real model (generating 10 real variable importances, each feature 10 real importances)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "X = nor_feature.values\n",
    "Y = dataset['Is_anxiety'].values\n",
    "cv_result = []\n",
    "cv = KFold(n_splits=10)\n",
    "for train_index, valid_index in cv.split(X):\n",
    "    train_x,test_x = X[train_index],X[valid_index]\n",
    "    train_y,test_y = Y[train_index], Y[valid_index]\n",
    "    clf = RandomForestClassifier(n_estimators=50,random_state=90)\n",
    "    clf.fit(train_x, train_y)\n",
    "    feat_importance = clf.feature_importances_\n",
    "    cv_result.append(feat_importance)\n",
    "importance = np.array(cv_result)\n",
    "print(importance.shape) # expected 10 * 412\n",
    "np.save('RF_importance_array/real-10fold.npy', importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
